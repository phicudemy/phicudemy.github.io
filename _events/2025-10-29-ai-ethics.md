---
title: چالش‌های اخلاقی هوش مصنوعی
slug: ai-ethics
people:
  - path: _people/hadisafaei.md
contents:
  - path: _contents/workshops.md
categories:
  - path: _categories/cogsci.md
  - path: _categories/philosophy.md
tags:
  - path: _tags/philosophyofscience.md
  - path: _tags/cognitivesciences.md
schedule: 'پنج‌شنبه‌ها، ساعت الی '
format:
  - online
  - inperson
start: 2025-11-12T20:30:00.000Z
sessions: 4
published: true
register: 'https://zarinp.al/753233'
stdregister: 'https://zarinp.al/753234'
---



<center>
<img 
       src="https://assets.tina.io/b6b0cb5c-4b1b-43f4-9bea-8d6867c09320/academy/fall2025/Poster.jpg" 
       alt=" "
       style="width: 75%; height:75%;" />
</center>
<br><br>
اکثر فیلسوفان آن‏قدر خوش‌بخت نیستند که در زمانه‌ای زندگی
کنند که به‏واسطۀ انقلاب‌های تکنولوژیک دست‏خوش تغییراتی اساسی در زندگی انسان‏هاست.
تغییرات اساسی در زندگی انسان‌ها عموماً مسائل جدیدی تولید می‌کنند که به‌واسطۀ
درگیرشدن با آن‌ها فیلسوفان فرصت پیدا می‌کنند تا افق‌های نظری تازه‌ای را
بگشایند. در این دورۀ کوتاه تلاش می‌کنیم تا برخی مسائل جدیدی که انقلاب دیجیتال و
به‌ویژه توسعۀ هوش مصنوعی ایجاد کرده‌ است را مرور کنیم. تازگی این مباحث و به‌ویژه
ماهیت بینارشته‌ای آن‌ها موجب می‌شود که به‌قول آرتور کوستلر، تلاش‌هایی از این
دست بیش‌تر شبیه نوعی خواب‌گردی‌ فکری باشد تا تحلیل منظم فلسفی. 

در این کارگاه چهارجلسه‏ای نخست تلاش می‌کنیم تا تصویری کلی
از مجموعه‌مسائل اخلاقی مربوط به توسعۀ هوش مصنوعی فراهم کنیم. تمرکز اصلیِ بحث در
این بخش معطوف به معرفی مسئلۀ «عدالت الگوریتمی» (algorithmic justice/fairness) خواهد بود. همان‌طورکه
خواهیم دید، یکی از مهم‌ترین مشکلات کاربرد هوش مصنوعی این است که به نظر می‌رسد
الگوریتم‌های هوش مصنوعی به بازتولید تبعیض و بی‌عدالتی علیه گروه‌های اقلیت مثل
زنان و سیاه‌پوستان منتهی شده‌اند. 

درادامه، تلاش می‌کنیم تا با کمی تفصیل به مسئلۀ «جهت‌دهی
الگوریتمی» (algorithmic influence) بپردازیم؛ این‌که آیا زیرساخت‌های دیجیتال مثل اینستاگرام،
یوتیوب، و موتور جست‌وجوی گوگل مجازند که با استفاده از داده‌هایی که از رفتار ما
در این شبکه‌ها استخراج کرده‌اند، دربارۀ نحوۀ نمایش محتواها برای ما تصمیم بگیرند
و بدین وسیله به‌شکلی غیرمستقیم به باورها، امیال، و رفتار فردی و سیاسی ما شکل
بدهند؟ همان‌طورکه خواهیم دید، مسئلۀ جهت‌دهی الگوریتمی نمونۀ جالب توجهی است که
می‌تواند به شکل‌گیری نوعی فلسفۀ سیاسی دیجیتال منتهی شود. 

درنهایت، به این پرسش خواهیم پرداخت که آیا ماشین‌های
هوشمند می‌توانند واجد منزلت اخلاقی (moral status) باشند؟ وقتی یک موجود واجد منزلت اخلاقی باشد ما نمی‌توانیم هرطور
که بخواهیم با او رفتار کنیم و اخلاقاً ناگزیریم که در تنظیم رفتارهایمان منافع آن
موجود را نیز در نظر بگیریم؛ مثلاً طرف‌داران گیاه‌خواری معتقدند که حیوانات واجد
منزلت اخلاقی‌اند و ما اخلاقاً مجاز نیستیم که برای تغذیه یا لذت بردن آن‌ها را پرورش
دهیم و مصرف کنیم. در این بخش می‌خواهیم به بحث دربارۀ این موضوع بپردازیم که آیا
ممکن است در آیندۀ نزدیک ماشین‌های هوشمندی داشته باشیم که واجد منزلت اخلاقی
باشند و درنتیجه دیگر نتوانیم با آن‌ها آن‌طور که می‌خواهیم رفتار کنیم؟ آیا استدلال‌های
فلسفی خوبی وجود دارد که نشان بدهد که بهره‌کشی از این ماشین‌های هوشمند آتی مستلزم
رفتاری فوق‌العاده غیراخلاقی، یعنی چیزی شبیه برده‌داری، خواهد بود؟ 

<br><br>

**برنامۀ کارگاه:**

- جلسۀ‌ اول: عدالت‌ الگوریتمی‌

- جلسۀ‌ دوم‌: جهت‌دهی‌ الگوریتمی‌

- جلسۀ سوم‌: به‌سوی‌ یک‌ فلسفۀ‌ سیاسی‌ دیجیتال‌

- جلسۀ‌ چهارم‌: منزلت‌ اخلاقی‌ هوش‌ مصنوعی‌

*** 

**محمدهادی صفایی** فارغ التحصیل مهندسی برق از پلی‌تکنیک تهران
و فارغ التحصیل دکتری فلسفۀ تحلیلی از پژوهشگاه دانش‌های بنیادی است. حوزه‌های پژوهشی
او شامل دلایل و عقلانیت، روان‌شناسی اخلاق، اخلاق باور، و مسائل اخلاقی هوش مصنوعی
است. وی هم‌اکنون پژوهش‌گر پژوهشگاه دانش‌های بنیادی و مسئول گروه مطالعاتی هوش مصنوعی
و علوم شناختی در پژوهشکدۀ فلسفۀ تحلیلی است. برای آشنایی بیش‏تر با حوزه‌های کاری
او می‌توانید به [این‌جا](https://philpeople.org/profiles/mohamad-hadi-safaei)  مراجعه کنید.

***

### اطلاعات برگزاری:

- ۴ جلسه

- زمان برگزاری: پنج‌شنبه‌ها ساعت . 

- تاریخ شروع: ۲۲ آبان ۱۴۰۴

- آدرس کلاس مجازی: قبل از هر جلسه **از طریق ای‌میلی که در زمان ثبت‌نام وارد کرده‌اید** اعلام می‌شود. 

- محل برگزاری کلاس حضوری: تهران، خیابان انقلاب، خیابان وصال شیرازی، کوچهٔ نایبی، پلاک ۲۳، اتاق ۱۱۵، آدرس روی نقشه: 

<iframe src="https://www.google.com/maps/embed?pb=!1m17!1m12!1m3!1d3239.9701159679107!2d51.400496999999994!3d35.702352999999995!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m2!1m1!2zMzXCsDQyJzA4LjUiTiA1McKwMjQnMDEuOCJF!5e0!3m2!1sen!2s!4v1727792460938!5m2!1sen!2s" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>


***
<br>

